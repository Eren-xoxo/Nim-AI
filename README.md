# Nim AI mit Q-Learning

Dieses Projekt implementiert eine KÃ¼nstliche Intelligenz (KI), die mithilfe von Q-Learning das klassische Spiel **Nim** erlernt und gegen menschliche Spieler antreten kann.

## ğŸ§  Ziel des Projekts

Das Ziel ist es, eine KI zu programmieren, die selbststÃ¤ndig durch Training lernt, optimale ZÃ¼ge zu machen, um das Spiel **Nim** zu gewinnen. AnschlieÃŸend kannst du gegen die KI in einer grafischen BenutzeroberflÃ¤che (GUI mit Pygame) antreten.

## ğŸ”— Repository-Struktur

```
Nim-AI-Template/
â”‚
â”œâ”€â”€ nim.py          # Spiellogik & Q-Learning KI (Hauptimplementierung)
â”œâ”€â”€ play.py         # Einstiegspunkt: Training & Spielstart
â”œâ”€â”€ game.py         # Grafische OberflÃ¤che (Pygame)
â”œâ”€â”€ test.py         # Tests fÃ¼r die KI-Funktionen
â””â”€â”€ README.md       # Dieses Dokument
```

## ğŸ“¦ Installation & Start

```bash
# Repository klonen
git clone https://github.com/patkordum/Nim-AI-template.git
cd Nim-AI-template

# Spiel starten (trainiert zuerst die KI und Ã¶ffnet GUI)
python play.py
```

## ğŸ” Funktionsweise der KI

Die KI nutzt **Q-Learning**, ein Verfahren des Reinforcement Learning. Dabei wird jeder mÃ¶gliche Spielzustand und jede mÃ¶gliche Aktion mit einem **Q-Wert** bewertet, der die QualitÃ¤t dieser Aktion in dem Zustand beschreibt.

### Zustand (State)

Ein Zustand ist die aktuelle Verteilung der Steine in den Haufen, z.â€¯B.:

```python
[1, 1, 3, 5]
```

### Aktion (Action)

Eine Aktion ist ein Tupel `(i, j)`, das bedeutet: â€Entferne **j** Steine aus Haufen **i**â€œ.
Beispiel:

```python
(3, 2)  # Entferne 2 Steine aus Haufen 3
```

### Q-Wert-Tabelle (`self.q`)

Diese speichert die Bewertung jeder (Zustand, Aktion)-Kombination.

```python
self.q[((1, 1, 3, 5), (3, 2))] = 0.75
```

### Q-Learning-Formel

Die Bewertung erfolgt durch:

```python
Q(s, a) â† old_q + alpha * (reward + future_q - old_q)
```

## ğŸ”§ Wichtige Methoden (nim.py)

### `get_q_value(state, action)`

Gibt den Q-Wert eines bestimmten Zustands und einer Aktion zurÃ¼ck (0, falls unbekannt).

### `update_q_value(state, action, old_q, reward, future_q)`

Aktualisiert den Q-Wert nach dem Q-Learning-Update-Regel.

### `best_future_reward(state)`

Gibt den hÃ¶chsten bekannten Q-Wert fÃ¼r mÃ¶gliche Folgeaktionen zurÃ¼ck.

### `choose_action(state, epsilon=True)`

WÃ¤hlt eine Aktion gemÃ¤ÃŸ einer Îµ-greedy-Strategie:

* Mit Wahrscheinlichkeit Îµ: zufÃ¤llige Aktion (Exploration)
* Mit Wahrscheinlichkeit 1â€¯â€“â€¯Îµ: beste bekannte Aktion (Exploitation)

## ğŸ§ª Testen (test.py)

Die Datei `test.py` enthÃ¤lt vorbereitete Tests fÃ¼r alle wichtigen Methoden. Du kannst sie starten mit:

```bash
python test.py
```

## ğŸ® Spielverlauf (game.py)

* GUI mit Pygame
* Du kannst mit der Maus Steine auswÃ¤hlen und entfernen
* Nach deinem Zug ist die KI dran

## ğŸ Trainingsstart (play.py)

Startet automatisch ein Training mit 1000 Partien und beginnt dann das Spiel:

```python
ai = train(1000)
start_game(ai)
```

## ğŸ“ˆ Weiterentwicklung

* Q-Werte speichern und wiederverwenden
* Spielmodi: Mensch gegen Mensch, KI gegen KI
* Anpassbare Anzahl an Haufen/Steinen
* MCTS oder Deep Q-Learning ergÃ¤nzen

## ğŸ“š Quellen & Tools

* Python 3
* Pygame
* Reinforcement Learning Prinzipien (Q-Learning)

---

Viel SpaÃŸ beim Ausprobieren â€“ und schlag die KI, wenn du kannst! ğŸ¤–
